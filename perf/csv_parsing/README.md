# CSV Parsing Benchmarks

## parse_baseline

The goal of this benchmark is to understand and evaluate the performance of parsing CSV using the [csv](https://docs.rs/csv/latest/csv/) crate.

The code for this is in [parse.rs](./benches/parse.rs). The benchmark is run on data generated by the `gen_data.py` script in this folder.

We first establish a few baseline metrics:
- Reading each file to memory sequentially.
- Reading each file to memory in parallel (using rayon).
- Iterating through every character after reading each file in parallel.

Then we bench mark the following:

- Iterate as a `csv::StringRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` with a single `ByteRecord` copy (effectively minimizing memory allocations per record).

### Running
```
cargo criterion --message-format=json > test.json;
cat test.json | python3 ../../utils/criterion_to_md.py;
```
- 
### Results

#### MacBook (Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz)

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|parse_baseline/seq_io_baseline|40.3|40.13|40.66|
|parse_baseline/par_io_baseline|31.82|31.26|32.44|
|parse_baseline/par_baseline_each_char|31.99|31.61|32.9|
|parse_baseline/csv_file_reader_string|635.14|604.86|679.58|
|parse_baseline/csv_file_reader_byte|621.76|609.42|635.8|
|parse_baseline/csv_file_reader_record_reference|210.75|201.15|221.2|

#### Intel(R) Core(TM) i5-10600K CPU @ 4.10GHz

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|parse_baseline/seq_io_baseline|33.78|33.76|33.81|
|parse_baseline/par_io_baseline|33.59|33.55|33.66|
|parse_baseline/par_baseline_each_char|33.43|33.33|33.48|
|parse_baseline/csv_file_reader_string|238.2|236.47|240.0|
|parse_baseline/csv_file_reader_byte|221.27|220.41|221.9|
|parse_baseline/csv_file_reader_record_reference|110.58|110.32|111.05|
### Conclusions

- StringRecord vs ByteRecord seems to make a marginal difference in this dataset.
- Reusing a ByteRecord makes a huge difference.

## Follow Up Questions

- Does the serde conversion path in the csv crate use a single ByteRecord?
    - Yes
- arrow2 uses a single ByteRecord for inferring schema, but uses a batch of ByteRecords for deserializing into arrow. Can it benefit from a single ByteRecord?
- How does arrow2_convert performance compare, where we use a statically typed schema, and use serde to convert to an intermediate struct?
- There are some complex match expressions in the csv library, and from prior experience these seem to cause a performance hit. Look into using a lookup table for optimization.
    - After further reading this seems to be optimization performed by LLVM:
        - [Example of a neat LLVM optimization](https://www.reddit.com/r/rust/comments/31kras/are_match_statements_constanttime_operations/)

## csv_to_arrow

The goal of this benchmark is to understand and evaluate the performance of parsing CSV to arrow. We evaluate parsing using [arrow2](https://github.com/jorgecarleitao/arrow2) and [arrow2_convert](https://github.com/DataEngineeringLabs/arrow2-convert).
