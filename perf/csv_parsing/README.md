# CSV Parsing Benchmarks

## parse_baseline

The goal of this benchmark is to understand and evaluate the performance of parsing CSV using the [csv](https://docs.rs/csv/latest/csv/) crate.

The code for this is in [parse.rs](./benches/parse.rs). The benchmark is run on data generated by the `gen_data.py` script in this folder.

We first establish a few baseline metrics:
- Reading each file to memory sequentially.
- Reading each file to memory in parallel (using rayon).
- Iterating through every character after reading each file in parallel.

Then we bench mark the following:

- Iterate as a `csv::StringRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` with a single `ByteRecord` copy (effectively minimizing memory allocations per record).

### Results

#### MacBook (Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz)

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|parse_baseline/seq_io_baseline|31.02|30.81|31.25|
|parse_baseline/par_io_baseline|30.18|29.91|30.55|
|parse_baseline/par_baseline_each_char|31.56|30.76|32.39|
|parse_baseline/csv_file_reader_string|569.78|560.81|579.72|
|parse_baseline/csv_file_reader_byte|556.56|550.49|563.05|
|parse_baseline/csv_file_reader_record_reference|194.39|188.26|201.0|

#### Intel(R) Core(TM) i5-10600K CPU @ 4.10GHz

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|kaggle_stock_data_benchmark/seq_io_baseline|180.19|180.08|180.32|
|kaggle_stock_data_benchmark/par_io_baseline|105.86|105.82|105.91|
|kaggle_stock_data_benchmark/par_baseline_each_char|105.75|105.55|105.88|
|kaggle_stock_data_benchmark/csv_file_reader_string|565.96|565.65|566.32|
|kaggle_stock_data_benchmark/csv_file_reader_byte|513.13|512.65|513.69|
|kaggle_stock_data_benchmark/csv_file_reader_record_reference|364.42|363.78|365.62|
### Conclusions

- StringRecord vs ByteRecord seems to make a marginal difference in this dataset.
- Reusing a ByteRecord makes a huge difference.

## Follow Up Questions

- Does the serde conversion path in the csv crate use a single ByteRecord?
    - Yes
- arrow2 uses a single ByteRecord for inferring schema, but uses a batch of ByteRecords for deserializing into arrow. Can it benefit from a single ByteRecord?
- How does arrow2_convert performance compare, where we use a statically typed schema, and use serde to convert to an intermediate struct?
- There are some complex match expressions in the csv library, and from prior experience these seem to cause a performance hit. Look into using a lookup table for optimization.
    - After further reading this seems to be optimization performed by LLVM:
        - [Example of a neat LLVM optimization](https://www.reddit.com/r/rust/comments/31kras/are_match_statements_constanttime_operations/)

## csv_to_arrow

The goal of this benchmark is to understand and evaluate the performance of parsing CSV to arrow. We evaluate parsing using [arrow2](https://github.com/jorgecarleitao/arrow2) and [arrow2_convert](https://github.com/DataEngineeringLabs/arrow2-convert).
