# CSV Parsing Benchmarks

## parse_baseline

The goal of this benchmark is to understand and evaluate the performance of parsing CSV using the [csv](https://docs.rs/csv/latest/csv/) crate.

The code for this is in [parse.rs](./benches/parse.rs). The benchmark is run on data generated by the `gen_data.py` script in this folder.

We first establish a few baseline metrics:
- Reading each file to memory sequentially.
- Reading each file to memory in parallel (using rayon).
- Iterating through every character after reading each file in parallel.

Then we bench mark the following:

- Iterate as a `csv::StringRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` making a new copy for each record
- Iterate as a `csv::ByteRecord` with a single `ByteRecord` copy (effectively minimizing memory allocations per record).

### Running
```
cargo criterion --message-format=json > test.json;
cat test.json | python3 ../../utils/criterion_to_md.py;
```
- 
### Results

#### MacBook (Intel(R) Core(TM) i7-8850H CPU @ 2.60GHz)

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|parse_baseline/seq_io_baseline|36.78|36.55|37.06|
|parse_baseline/par_io_baseline|29.71|29.51|29.88|
|parse_baseline/par_baseline_iter_char|29.58|29.32|29.96|
|parse_baseline/csv_file_reader_string|631.1|623.7|637.7|
|parse_baseline/csv_file_reader_byte|609.83|597.26|625.39|
|parse_baseline/async_io_reader_reference|472.44|433.7|519.55|
|parse_baseline/csv_file_reader_record_reference|200.71|197.34|205.3|

#### Intel(R) Core(TM) i5-10600K CPU @ 4.10GHz

|benchmark|estimate (ms) |lower (ms)|upper (ms)|
|---------|--------|-----|-----|
|parse_baseline/seq_io_baseline|35.49|35.46|35.54|
|parse_baseline/par_io_baseline|34.25|34.22|34.33|
|parse_baseline/par_baseline_iter_char|34.06|34.05|34.09|
|parse_baseline/csv_file_reader_string|194.49|194.41|194.58|
|parse_baseline/csv_file_reader_byte|181.9|181.76|182.0|
|parse_baseline/async_io_reader_reference|236.45|234.96|238.05|
|parse_baseline/csv_file_reader_record_reference|113.94|113.82|114.09|
### Conclusions

- StringRecord vs ByteRecord seems to make a marginal difference in this dataset.
- Reusing a ByteRecord makes a huge difference.

## Follow Up Questions

- Does the serde conversion path in the csv crate use a single ByteRecord?
    - Yes
- arrow2 uses a single ByteRecord for inferring schema, but uses a batch of ByteRecords for deserializing into arrow. Can it benefit from a single ByteRecord?
- How does arrow2_convert performance compare, where we use a statically typed schema, and use serde to convert to an intermediate struct?
- There are some complex match expressions in the csv library, and from prior experience these seem to cause a performance hit. Look into using a lookup table for optimization.
    - After further reading this seems to be optimization performed by LLVM:
        - [Example of a neat LLVM optimization](https://www.reddit.com/r/rust/comments/31kras/are_match_statements_constanttime_operations/)

## csv_to_arrow

The goal of this benchmark is to understand and evaluate the performance of parsing CSV to arrow. We evaluate parsing using [arrow2](https://github.com/jorgecarleitao/arrow2) and [arrow2_convert](https://github.com/DataEngineeringLabs/arrow2-convert).
